{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of OpenCV + FastAI for video capture\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### For reference:\n",
    "<img src='https://i.pinimg.com/originals/fa/bb/70/fabb7087b0cffe30530e7df9ec1d0b88.png' width=\"400\" height=\"500\"></img>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-04T05:34:51.230527Z",
     "iopub.status.busy": "2021-03-04T05:34:51.230157Z",
     "iopub.status.idle": "2021-03-04T05:34:52.147712Z",
     "shell.execute_reply": "2021-03-04T05:34:52.147256Z",
     "shell.execute_reply.started": "2021-03-04T05:34:51.230440Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -Uqq fastbook\n",
    "# import fastbook\n",
    "# fastbook.setup_book()\n",
    "\n",
    "# RUN_NAME = '20210116-2147 - arch=xresnet50 - samples=1000 frozen=3 epochs=3 bs=20 res=300 _data=external preuntrained percent=88'\n",
    "# RUN_NAME = '20210116-2108 - arch=xresnet18 - samples=480 frozen=2 epochs=3 bs=8 res=300 _data=frank_pretrained=false_percent=71'\n",
    "\n",
    "# DEAD RUN_NAME = '20210118-2100 - arch=xresnet50 - samples=1000 frozen=0 epochs=25 bs=20 res=300 _data=external'\n",
    "# RUN_NAME = '200927-0730-RESNET101-384px-FALL-ft3f4'\n",
    "# RUN_NAME = '20210119-0130 - arch=xresnet50 - samples=1000 frozen=0 epochs=25 bs=20 res=300 _data=external'\n",
    "# RUN_NAME = '20210119-2152 - arch=xresnet50_deep - samples=1000 frozen=0 epochs=25 bs=20 res=300 _data=external'\n",
    "# RUN_NAME = '20210118-2000 - arch=xresnet50 - samples=1000 frozen=0 epochs=25 bs=20 res=300 _data=external'\n",
    "\n",
    "# RUN_NAME = '20210121-0017 - arch=xresnet50_deep - samples=3000 frozen=0 epochs=12 bs=20 res=300 _data=external'\n",
    "# RUN_NAME='20210122-0037 - arch=xresnet50_deep - samples=3000 frozen=1 epochs=40 bs=16 res=360 _data=external'\n",
    "# RUN_NAME = '20210122-2356 - arch=xresnet50_deep - samples=3000 frozen=1 epochs=40 bs=16 res=360 _data=external'\n",
    "# RUN_NAME = '20210123-2127 - arch=xresnet50_deep - samples=2000 frozen=1 epochs=22 bs=16 res=360 _data=external'\n",
    "# RUN_NAME = '20210126-0759 - arch=xresnet50_deep - samples=1000 frozen=1 epochs=30 bs=16 res=360 _data=combined1'\n",
    "# RUN_NAME = '20210126-1840 - arch=xresnet50_deep - samples=1000 frozen=1 epochs=30 bs=16 res=360 _data=combined1'\n",
    "# RUN_NAME = '20210127-1717 - arch=xresnet50 - samples=1100 frozen=1 epochs=20 bs=28 res=280 _data=combined2'\n",
    "# RUN_NAME = '20210127-2251 - arch=xresnet50 - samples=1100 frozen=1 epochs=40 bs=28 res=280 _data=combined2'\n",
    "# RUN_NAME = '20210128-1251 - arch=xresnet50 - samples=1100 frozen=1 epochs=40 bs=28 res=280 _data=combined2'\n",
    "# RUN_NAME = '20210128-1704 - arch=xresnet50 - samples=1100 frozen=1 epochs=40 bs=28 res=280 _data=combined2'\n",
    "RUN_NAME = '20210129-0332 - arch=xresnet50 - samples=620 frozen=1 epochs=40 bs=28 res=280 _data=frank-proc2-L'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PRED_THRESHOLD = 0.85\n",
    "\n",
    "epoch_num = 23\n",
    "\n",
    "\n",
    "\n",
    "SAVE_IMAGES_TO_FILE = False  # flag if we want to capture the image to disk\n",
    "\n",
    "SYMBOL = None\n",
    "\n",
    "RESOLUTION = 280\n",
    "\n",
    "PREPROCESS_FRAMES = True\n",
    "PP_SHOW_PROCESSED_CHANNELS = True\n",
    "\n",
    "\n",
    "# from fastbook import *\n",
    "from fastbook import *\n",
    "from fastai.vision.all import *\n",
    "\n",
    "\n",
    "from fastai.vision.widgets import *\n",
    "import fastai.vision\n",
    "import fastai\n",
    "from fastai.learner import *\n",
    "import fastprogress\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for an available GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-04T05:34:52.148479Z",
     "iopub.status.busy": "2021-03-04T05:34:52.148365Z",
     "iopub.status.idle": "2021-03-04T05:34:52.154589Z",
     "shell.execute_reply": "2021-03-04T05:34:52.153650Z",
     "shell.execute_reply.started": "2021-03-04T05:34:52.148467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:              True\n",
      "CUDA device count:           1\n",
      "Current CUDA Device index:   0\n",
      "Current CUDA Device:         GeForce RTX 2070 SUPER\n",
      "\n",
      "fastai version:              2.2.5\n",
      "cuda version:                10.1\n",
      "torch version:               1.7.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print('CUDA available: '.ljust(28), torch.cuda.is_available())\n",
    "print('CUDA device count: '.ljust(28), torch.cuda.device_count())\n",
    "\n",
    "current_device = torch.cuda.current_device()\n",
    "print('Current CUDA Device index: '.ljust(28), current_device)\n",
    "print('Current CUDA Device: '.ljust(28), torch.cuda.get_device_name(current_device))\n",
    "print()\n",
    "print(f'fastai version:              {fastai.__version__}')\n",
    "\n",
    "print(f'cuda version:                {torch.version.cuda}')\n",
    "print(f'torch version:               {torch.__version__}')\n",
    "# print(f'python version:              {python_version()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-04T05:34:52.155811Z",
     "iopub.status.busy": "2021-03-04T05:34:52.155568Z",
     "iopub.status.idle": "2021-03-04T05:34:53.585516Z",
     "shell.execute_reply": "2021-03-04T05:34:53.584622Z",
     "shell.execute_reply.started": "2021-03-04T05:34:52.155787Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/20210129-0332 - arch=xresnet50 - samples=620 frozen=1 epochs=40 bs=28 res=280 _data=frank-proc2-L_23.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-659af8637a28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSAVE_IMAGES_TO_FILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlearn_inf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../models/{RUN_NAME}.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'models/{RUN_NAME}_{epoch_num}.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_inf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Loaded.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.8/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(file, model, opt, with_opt, device, strict)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mhasopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasopt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/learn/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/20210129-0332 - arch=xresnet50 - samples=620 frozen=1 epochs=40 bs=28 res=280 _data=frank-proc2-L_23.pth'"
     ]
    }
   ],
   "source": [
    "if not SAVE_IMAGES_TO_FILE:\n",
    "    learn_inf = load_learner(f'../models/{RUN_NAME}.pkl', cpu=False)\n",
    "    load_model(f'models/{RUN_NAME}_{epoch_num}.pth', learn_inf, with_opt=False, opt=Adam)\n",
    "    print('Model Loaded.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T02:29:04.006634Z",
     "iopub.status.busy": "2021-01-27T02:29:04.006376Z",
     "iopub.status.idle": "2021-01-27T02:29:04.011539Z",
     "shell.execute_reply": "2021-01-27T02:29:04.011069Z",
     "shell.execute_reply.started": "2021-01-27T02:29:04.006609Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "# Needed to pass into the DataBlock    \n",
    "def get_fnames(path): \n",
    "    retlist = get_image_files('../data/frank/Training_Set')\n",
    "    return random.sample(retlist, 500) \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "signs = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_fnames, \n",
    "    splitter=RandomSplitter(valid_pct=0.3, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=CropPad(RESOLUTION, pad_mode='zeros'))\n",
    "#    ,    batch_tfms=aug_transforms(do_flip=True, size=RESOLUTION, batch=False, max_zoom=1.0, mult=1, pad_mode='zeros'))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T02:29:04.605566Z",
     "iopub.status.busy": "2021-01-27T02:29:04.605307Z",
     "iopub.status.idle": "2021-01-27T02:29:04.831357Z",
     "shell.execute_reply": "2021-01-27T02:29:04.831032Z",
     "shell.execute_reply.started": "2021-01-27T02:29:04.605542Z"
    }
   },
   "source": [
    "funky_path = f'../data/frank/Training_Set'\n",
    "\n",
    "dls = signs.dataloaders(funky_path, bs=32)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T02:29:05.092808Z",
     "iopub.status.busy": "2021-01-27T02:29:05.092558Z",
     "iopub.status.idle": "2021-01-27T02:29:05.273889Z",
     "shell.execute_reply": "2021-01-27T02:29:05.273524Z",
     "shell.execute_reply.started": "2021-01-27T02:29:05.092785Z"
    }
   },
   "source": [
    "test_dl = dls.test_dl(get_fnames(''), with_labels=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T02:29:05.760338Z",
     "iopub.status.busy": "2021-01-27T02:29:05.760089Z",
     "iopub.status.idle": "2021-01-27T02:29:05.884428Z",
     "shell.execute_reply": "2021-01-27T02:29:05.883974Z",
     "shell.execute_reply.started": "2021-01-27T02:29:05.760313Z"
    }
   },
   "source": [
    "# get_fnames('')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T02:29:08.609928Z",
     "iopub.status.busy": "2021-01-27T02:29:08.609660Z",
     "iopub.status.idle": "2021-01-27T02:29:12.705623Z",
     "shell.execute_reply": "2021-01-27T02:29:12.705308Z",
     "shell.execute_reply.started": "2021-01-27T02:29:08.609895Z"
    }
   },
   "source": [
    "learn_inf.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-03-04T05:34:53.585860Z",
     "iopub.status.idle": "2021-03-04T05:34:53.586025Z",
     "shell.execute_reply": "2021-03-04T05:34:53.585941Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_camera() -> cv.VideoCapture:\n",
    "    '''\n",
    "    Set up the camera source\n",
    "    '''\n",
    "#     cap = cv.VideoCapture(0)\n",
    "    # cap = cv.VideoCapture('http://127.0.0.1:4747/video')\n",
    "#     cap = cv.VideoCapture('http://10.0.0.67:4747/video')  # S7\n",
    "    cap = cv.VideoCapture('http://10.0.0.74:4747/video')  # N10\n",
    "\n",
    "    # cap = cv.VideoCapture('Droidcam')\n",
    "#     cap = cv.VideoCapture('http://10.0.0.144:4747/video')  # N8\n",
    "    \n",
    "    print(f'Autofocus status: {cap.set(cv.CAP_PROP_AUTOFOCUS, 1)}')\n",
    "    print(f'Manual focus to shortest distance: {cap.set(cv.CAP_PROP_FOCUS, 0)}')\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video stream or file!\")\n",
    "    \n",
    "    return cap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def close_camera():\n",
    "    '''\n",
    "    Close all capture devices and destroy open capture windows\n",
    "    '''\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def print_stats():\n",
    "    '''\n",
    "    Print some basic stats to stdout\n",
    "    '''\n",
    "    \n",
    "    print(f'Frame shape = {frame.shape}')\n",
    "    print(f'Total number of Frames = {nframe}')\n",
    "    print(f'Number of frames processed = {n_proc_frames // PROC_NTH_FRAME}')\n",
    "    \n",
    "    \n",
    "    \n",
    "# @TODO: Factor out the directory creation logic - slow/redundant    \n",
    "def save_images(frame, pr_frame):\n",
    "    '''\n",
    "    write small and large images to jpeg\n",
    "    '''\n",
    "    symbol_dir = SYMBOL\n",
    "    \n",
    "    #seperate the directory path\n",
    "    datadir_small = f'../data/{maindir}-S/{symbol_dir}'\n",
    "    datadir_large = f'../data/{maindir}-L/{symbol_dir}'\n",
    "\n",
    "    # build the entire directory structure if it doesn't exist\n",
    "#     if not os.path.isdir(datadir_small):\n",
    "#         os.makedirs(datadir_small)\n",
    "        \n",
    "    if not os.path.isdir(datadir_large):\n",
    "        os.makedirs(datadir_large)\n",
    "    \n",
    "    # create a directory+filename template\n",
    "#     ftemplate_small = f'{datadir_small}/{file_prefix}-{n_save_frames}.jpg'\n",
    "    ftemplate_large = f'{datadir_large}/{file_prefix}-{n_save_frames}.jpg'\n",
    "    \n",
    "    # write the image to a file\n",
    "#     cv.imwrite(ftemplate_small, pr_frame)\n",
    "#     cv.imwrite(ftemplate_large, frame)\n",
    "    cv.imwrite(ftemplate_large, pr_frame)\n",
    "    \n",
    "    frame = cv.putText(frame, f'Saved Frame {SYMBOL} #{n_save_frames}', \n",
    "                   org=(20,40), fontFace=cv.FONT_HERSHEY_PLAIN, \n",
    "                   fontScale=2, color=(0,255,255), thickness=2,\n",
    "                   lineType=cv.LINE_AA) \n",
    "    \n",
    "    # Display the frame with the writing on it\n",
    "    cv.imshow('What the Camera Sees:',frame)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Open the video camera, loop for every Frame, massage the image and make a prediction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the main code cel.  It has 2 purposes. When you hit the spacebar, it will either:\n",
    "1. Make an ASL alphabet translation or \n",
    "2. If SAVE_IMAGES_TO_FILE is True, it will save an image to the data dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-03-04T05:34:53.586400Z",
     "iopub.status.idle": "2021-03-04T05:34:53.586559Z",
     "shell.execute_reply": "2021-03-04T05:34:53.586480Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.vision  import *\n",
    "import torch\n",
    "\n",
    "PROC_NTH_FRAME = 6  # Skip every N-1 frames - increase this if your computer lags\n",
    "\n",
    "maindir = 'frank-proc2'  # these are image saving parameters dir/file\n",
    "file_prefix = 'fproc2'\n",
    "\n",
    "n_proc_frames, nframe = 0,0  # number of frames\n",
    "n_save_frames = 0  # number of captured frames for saving to file\n",
    "\n",
    "# declare here to widen scope\n",
    "pred, probs, pred_idx = [0], [0], 0\n",
    "frame, pr_frame = None, None\n",
    "\n",
    "if SAVE_IMAGES_TO_FILE:\n",
    "    SYMBOL = input('Enter Symbol of interest: ')[0]\n",
    "    \n",
    "cap = setup_camera()\n",
    "# cap.set(cv.CAP_PROP_FPS, 10)  # Doesn't work?\n",
    "\n",
    "\n",
    "PP_REMOVE_BACKGROUND = True  # Choose this if you want to try to erase the background\n",
    "PP_CANNY_EDGE = True  # Choose this to add edge highlighting\n",
    "\n",
    "if PP_REMOVE_BACKGROUND:\n",
    "    backSub = cv.createBackgroundSubtractorKNN(history=500, dist2Threshold=300)  # Background Subtractor\n",
    "    \n",
    "    ## Create kernels to apply filters\n",
    "    kernel1 = cv.getStructuringElement(cv.MORPH_ELLIPSE,(1,1))\n",
    "    kernel2 = cv.getStructuringElement(cv.MORPH_ELLIPSE,(2,2))\n",
    "    kernel3 = cv.getStructuringElement(cv.MORPH_ELLIPSE,(3,3))\n",
    "    kernel5 = cv.getStructuringElement(cv.MORPH_ELLIPSE,(5,5))\n",
    "    # kernel3 = np.ones((3,3),np.uint8)  # kernel of ones for masking\n",
    "    # kernel5 = np.ones((5,5), np.uint8)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-03-04T05:34:53.586903Z",
     "iopub.status.idle": "2021-03-04T05:34:53.587058Z",
     "shell.execute_reply": "2021-03-04T05:34:53.586980Z"
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "# \"Game\" Loop ... for every frame\n",
    "while(cap.isOpened()):\n",
    "    nframe += 4\n",
    "    ret, frame = cap.read()  # Capture frame\n",
    "    wait_ret = cv.waitKey(1)  # key char value if any\n",
    "\n",
    "    # Break out of the loop if the user presses 'Q'\n",
    "    if wait_ret & 0xFF == ord('q'):\n",
    "        print_stats()\n",
    "        break\n",
    "     \n",
    "    # only process the rest if the capture was successful\n",
    "    if not ret:\n",
    "        print(\"Can't read frame from capture source!\")\n",
    "        break  # break out of loop to let the camera close\n",
    "\n",
    "\n",
    "    # mirror the image horizontally\n",
    "    frame = cv.flip(frame, 1)\n",
    "\n",
    "    # This (background removal) processing must be done every frame, regardless.\n",
    "    pr_frame = cv.resize(frame[:, 80:-80], (RESOLUTION, RESOLUTION))\n",
    "    #  pr_frame = np.copy(frame[:,80:-80])\n",
    "\n",
    "    if PP_REMOVE_BACKGROUND:\n",
    "        fg_mask = backSub.apply(pr_frame, learningRate=0.005)  # initial background subtraction\n",
    "\n",
    "    # process only if the space key is hit and\n",
    "    # only process every PROC_NTH_FRAME frames \n",
    "    if (nframe % PROC_NTH_FRAME == 0):  # and wait_ret & 0xFF == ord(' ')  \n",
    "        n_proc_frames +=1  # num processed frames\n",
    "\n",
    "\n",
    "\n",
    "        if PREPROCESS_FRAMES:\n",
    "    \n",
    "            # remove color (different skin tones, light,etc)\n",
    "            pr_frame_G = cv.cvtColor(pr_frame, cv.COLOR_BGR2GRAY)  \n",
    "\n",
    "            if PP_REMOVE_BACKGROUND:\n",
    "\n",
    "                fg_mask = cv.morphologyEx(fg_mask, cv.MORPH_OPEN, kernel1, iterations=20)  # remove background blocks\n",
    "                fg_mask = cv.morphologyEx(fg_mask, cv.MORPH_CLOSE, kernel5, iterations=1)  # remove foreground blocks\n",
    "                fg_mask = cv.medianBlur(fg_mask,5)  # remove salt and pepper\n",
    "                fg_mask = cv.dilate(fg_mask, kernel5, iterations = 1)  # dilate the mask\n",
    "\n",
    "                fg_frame = cv.bitwise_and(pr_frame, pr_frame, mask=fg_mask)  # erase the background\n",
    "\n",
    "                fg_frame_G = cv.cvtColor(fg_frame, cv.COLOR_BGR2GRAY)  # convert to gray\n",
    "                fg_frame_G = cv.convertScaleAbs(fg_frame_G, alpha=1.2, beta=0)  # increase contrast\n",
    "\n",
    "\n",
    "                if PP_CANNY_EDGE:  # add canny edge at the end to maintain contrast\n",
    "                    fg_frame_canny = cv.Canny(fg_frame,50,200)  # Canny edge detection\n",
    "                    fg_frame_canny = cv.dilate(fg_frame_canny, kernel1)  # increase the line width\n",
    "        #             fg_frame_canny = cv.morphologyEx(fg_frame_canny, cv.MORPH_GRADIENT, kernel5)\n",
    "    #                 fg_frame_G = cv.add(fg_frame,fg_frame_canny)  # add the edges back to the masked image.\n",
    "\n",
    "            ## We now have 3 channels - grey, masked-grey and canny ... we combine them \n",
    "            pr_frame[:,:,0] = pr_frame_G  # first channel is grey\n",
    "            pr_frame[:,:,1] = fg_frame_G  # second channel is with masked background\n",
    "            pr_frame[:,:,2] = fg_frame_canny  # third channel is canny\n",
    "\n",
    "#             np.copyto(pr_frame[:,:,0], pr_frame_G)\n",
    "#             np.copyto(pr_frame[:,:,1], fg_frame_G)\n",
    "#             np.copyto(pr_frame[:,:,2], fg_frame_canny)\n",
    "\n",
    "\n",
    "            if PP_SHOW_PROCESSED_CHANNELS:\n",
    "                cv.imshow('Grey Scale Channel', pr_frame_G)\n",
    "                cv.imshow('Hidden Background', fg_frame_G)\n",
    "                cv.imshow('Canny Edge Detection', fg_frame_canny)\n",
    "        \n",
    "        \n",
    "        # Display the frame that we pass through the predictor\n",
    "        cv.imshow('What the Predictor Sees:', pr_frame)\n",
    "\n",
    "        if SAVE_IMAGES_TO_FILE :\n",
    "            if wait_ret & 0xFF == ord(' '):  # only save when pressing the spacebar\n",
    "                n_save_frames = n_save_frames + 1\n",
    "                save_images(frame, pr_frame)\n",
    "            continue  # no need to predict\n",
    "\n",
    "        # create the prediction\n",
    "        with learn_inf.no_bar():\n",
    "            img = PILImage.create(cv.cvtColor(pr_frame, cv.COLOR_BGR2RGB))\n",
    "            pred,pred_idx,probs = learn_inf.predict(img)\n",
    "            \n",
    "           \n",
    "           \n",
    "        # write the prediction as text on the frame\n",
    "        if probs[pred_idx.long()] > PRED_THRESHOLD:\n",
    "            frame = cv.putText(frame, f'Predict: {pred}, Conf: {probs[pred_idx]:.02f}', \n",
    "                               org=(20,40), fontFace=cv.FONT_HERSHEY_PLAIN, \n",
    "                               fontScale=2, color=(0,255,255), thickness=2,\n",
    "                               lineType=cv.LINE_AA) \n",
    "\n",
    "        # Display the original frame\n",
    "        cv.imshow('What the Camera Sees:',frame)\n",
    "\n",
    "# Release the capture object\n",
    "close_camera()\n",
    "# dec_inp.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-23T06:15:21.779062Z",
     "iopub.status.busy": "2021-01-23T06:15:21.778831Z",
     "iopub.status.idle": "2021-01-23T06:15:21.866777Z",
     "shell.execute_reply": "2021-01-23T06:15:21.866388Z",
     "shell.execute_reply.started": "2021-01-23T06:15:21.779040Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f = cv.cvtColor(pr_frame, cv.COLOR_BGR2RGB)\n",
    "timg = PILImage.create(f)\n",
    "type(timg)\n",
    "# learn_inf.predict(timg)\n",
    "timg.show()\n",
    "\n",
    "str(timg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-03-04T05:34:53.587377Z",
     "iopub.status.idle": "2021-03-04T05:34:53.587531Z",
     "shell.execute_reply": "2021-03-04T05:34:53.587454Z"
    }
   },
   "outputs": [],
   "source": [
    "close_camera()                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-19T09:52:40.639847Z",
     "iopub.status.busy": "2020-09-19T09:52:40.639632Z",
     "iopub.status.idle": "2020-09-19T09:52:40.642608Z",
     "shell.execute_reply": "2020-09-19T09:52:40.642059Z",
     "shell.execute_reply.started": "2020-09-19T09:52:40.639824Z"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# The rest of this file is for reference only.  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# Snippets\n",
    "\n",
    "```python\n",
    "# rotate the image\n",
    "frame = cv.rotate(frame, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-03-04T05:34:53.587831Z",
     "iopub.status.idle": "2021-03-04T05:34:53.587993Z",
     "shell.execute_reply": "2021-03-04T05:34:53.587910Z"
    }
   },
   "outputs": [],
   "source": [
    "# learn.export(f'../models/{RUN_NAME}.pkl')\n",
    "# path = Path('../models')\n",
    "# path.ls(file_exts='.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
